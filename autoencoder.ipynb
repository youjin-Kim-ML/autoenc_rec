{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\" # 할당된 gpu 번호\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "#session = tf.compat.v1.Session(config=config)\n",
    "import json\n",
    "def load_json(fname):\n",
    "    with open(fname) as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "train = load_json(\"train.json\")\n",
    "val = load_json(\"val.json\")\n",
    "test = load_json(\"test.json\")\n",
    "# for i in range(len(val)):\n",
    "#     train.append(val[i])\n",
    "data = train+val+test\n",
    "s = []\n",
    "t =[]\n",
    "play_ = []\n",
    "for i in range(len(data)):\n",
    "    t.append(data[i][\"tags\"])\n",
    "    s.append(data[i][\"songs\"])\n",
    "    play_.append(data[i][\"plylst_title\"])\n",
    "    \n",
    "tags = []\n",
    "for i in t:\n",
    "    abc = []\n",
    "    for j in i:\n",
    "        abc.append(str(j))  \n",
    "    tags.append(abc)\n",
    "songs = []\n",
    "for i in s:\n",
    "    abc = []\n",
    "    for j in i:\n",
    "        abc.append(str(j))  \n",
    "    songs.append(abc)\n",
    "title = []\n",
    "for i in play_:\n",
    "    abc = []\n",
    "    for j in i:\n",
    "        abc.append(str(j))  \n",
    "    title.append(abc)\n",
    "\n",
    "tags_ = [' '.join(sentence) for sentence in tags]\n",
    "songs_ = [' '.join(sentence) for sentence in songs]\n",
    "title_ = [' '.join(sentence) for sentence in title]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", min_df=2)\n",
    "vect.fit(tags_)\n",
    "len(vect.vocabulary_)\n",
    "\n",
    "vect_s = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=4)\n",
    "vect_s.fit(songs_)\n",
    "len(vect_s.vocabulary_)\n",
    "\n",
    "vect_ti = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=5)\n",
    "vect_ti.fit(title_)\n",
    "len(vect_ti.vocabulary_)\n",
    "\n",
    "train_  = vect.transform(tags_)\n",
    "train_s  = vect_s.transform(songs_)\n",
    "train_ti  = vect_ti.transform(title_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_meta= load_json(\"song_meta.json\")\n",
    "\n",
    "genre_meta = load_json(\"genre_gn_all.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_basket = []\n",
    "for i in songs:\n",
    "    basket = []\n",
    "    for j in i:\n",
    "        basket.append(int(j))\n",
    "    song_basket.append(basket)\n",
    "artist_basket=[]\n",
    "for  i in songs:\n",
    "    poo=[]\n",
    "    for  j in i:\n",
    "        poo.append(int(j))\n",
    "    artist_basket.append(poo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_cross_playlist(tr_songs, song_meta):\n",
    "    genre_cross_playlist = []\n",
    "    for playlist in tr_songs:\n",
    "        genre = []\n",
    "        #print(playlist)\n",
    "        for song in playlist:\n",
    "            #genre.append(song)\n",
    "            genre.extend(song_meta[song][\"artist_name_basket\"])\n",
    "        genre_cross_playlist.append(genre)\n",
    "    return genre_cross_playlist\n",
    "\n",
    "b = get_genre_cross_playlist(artist_basket,song_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_ = [' '.join(sentence) for sentence in b]\n",
    "vect_artist = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",min_df=3)\n",
    "vect_artist.fit(artist_)\n",
    "len(vect_artist.vocabulary_)\n",
    "train_artist  = vect_artist.transform(artist_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<148826x48164 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6812635 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "def denoising(songs):\n",
    "    a= []\n",
    "    d = 1\n",
    "    for _list in songs:\n",
    "        sample_list = []\n",
    "        if len(_list) < 9:\n",
    "            a.append(_list)\n",
    "            d\n",
    "            continue\n",
    "        for i in range(1):\n",
    "            new_list = copy.deepcopy(_list)\n",
    "            for i in range(int(len(new_list) *0.3)):\n",
    "                new_list.remove(random.choice(new_list))\n",
    "            a.append(new_list)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148826"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttags = denoising(tags)\n",
    "ssongs = denoising(songs)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags__ = [' '.join(sentence) for sentence in ttags]\n",
    "songs__ = [' '.join(sentence) for sentence in ssongs]\n",
    "#title__ = [' '.join(sentence) for sentence in aartist]\n",
    "\n",
    "train_d  = vect.transform(tags__)\n",
    "train_s_d  = vect_s.transform(songs__)\n",
    "#train_artist_d  = vect_artist.transform(title__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12381, 187516, 1393)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_),len(vect_s.vocabulary_),len(vect_ti.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4178615 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "r = scipy.sparse.hstack([train_s_d,train_d])\n",
    "r = csr_matrix(r)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5740773 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_y = scipy.sparse.hstack([train_s,train_])\n",
    "r_y = csr_matrix(r_y)\n",
    "r_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 4178615 stored elements in Compressed Sparse Row format>,\n",
       " <148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 5740773 stored elements in Compressed Sparse Row format>,\n",
       " <148826x48164 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6812635 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r,r_y,train_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<148826x12381 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 450884 stored elements in Compressed Sparse Row format>,\n",
       "  <148826x187516 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 3727731 stored elements in Compressed Sparse Row format>),\n",
       " (<148826x12381 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 498134 stored elements in Compressed Sparse Row format>,\n",
       "  <148826x187516 sparse matrix of type '<class 'numpy.int64'>'\n",
       "  \twith 5242639 stored elements in Compressed Sparse Row format>),\n",
       " <148826x48164 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6812635 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_d,train_s_d),(train_,train_s),train_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, add,Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def autoEncoder(X):\n",
    "    '''\n",
    "    Autoencoder for Collaborative Filter Model\n",
    "    '''\n",
    "    users_items_matrix= X\n",
    "    #print(users_items_matrix.shape,content_info.shape)\n",
    "    \n",
    "    # Input\n",
    "    input_layer   = Input(shape=(users_items_matrix.shape[1],), name='UserScore')\n",
    "    #input_content = Input(shape=(content_info.shape[1],), name='Itemcontent')\n",
    "    \n",
    "    # Encoder\n",
    "    # -----------------------------\n",
    "    enc = Dense(256, activation='sigmoid', name='EncLayer1',bias_initializer='zeros',kernel_initializer='glorot_uniform')(input_layer)\n",
    "\n",
    "    # Content Information\n",
    "    #x_content = Embedding(48165, 50, input_length=content_info.shape[1])(input_content)\n",
    "    #x_content = Flatten()(x_content)\n",
    "    #x_content = Dense(128, activation='selu', \n",
    "    #                           name='ItemLatentSpace')(x_content)\n",
    "    # Latent Space\n",
    "    # -----------------------------\n",
    "    #lat_space = Dense(256, activation='sigmoid', name='UserLatentSpace')(enc)\n",
    "    \n",
    "    #lat_space= Concatenate(name='LatentSpace')([enc, x_content])\n",
    "    lat_space = Dropout(0.25, name='Dropout')(enc) # Dropout\n",
    "\n",
    "    # Decoder\n",
    "    # -----------------------------\n",
    "    dec = Dense(256, activation='sigmoid', name='DecLayer1')(lat_space)\n",
    "\n",
    "    # Output\n",
    "    output_layer = Dense(users_items_matrix.shape[1], activation='sigmoid', name='UserScorePred',bias_initializer='zeros',kernel_initializer='glorot_uniform')(dec)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    model = Model(input_layer, output_layer)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "UserScore (InputLayer)       (None, 199897)            0         \n",
      "_________________________________________________________________\n",
      "EncLayer1 (Dense)            (None, 256)               51173888  \n",
      "_________________________________________________________________\n",
      "Dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "DecLayer1 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "UserScorePred (Dense)        (None, 199897)            51373529  \n",
      "=================================================================\n",
      "Total params: 102,613,209\n",
      "Trainable params: 102,613,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "# Build model\n",
    "X = r\n",
    "model = autoEncoder(X)\n",
    "#model = multi_gpu_model(model, gpus=2)\n",
    "#model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(optimizer = Adam(lr=0.01), loss='binary_crossentropy')\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<148826x48164 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6812635 stored elements in Compressed Sparse Row format>,\n",
       " 115071,\n",
       " 23015,\n",
       " 10740,\n",
       " 148826)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_artist,len(train),len(val),len(test),len(train)+len(val)+len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_artist = train_artist[115071:115071+23015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 5740773 stored elements in Compressed Sparse Row format>,\n",
       " <148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 4178615 stored elements in Compressed Sparse Row format>,\n",
       " <23015x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 400286 stored elements in Compressed Sparse Row format>,\n",
       " <23015x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 298913 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_r_y=r_y[115071:115071+23015]\n",
    "val_r_x=r[115071:115071+23015]\n",
    "r_y,r,val_r_y,val_r_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 4178615 stored elements in Compressed Sparse Row format>,\n",
       " <148826x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 5740773 stored elements in Compressed Sparse Row format>,\n",
       " <23015x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 298913 stored elements in Compressed Sparse Row format>,\n",
       " <23015x199897 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 400286 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r,r_y,val_r_x,val_r_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yjkim/anaconda3/envs/allml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 148826 samples, validate on 23015 samples\n",
      "Epoch 1/30\n",
      "148826/148826 [==============================] - 349s 2ms/step - loss: 0.0021 - val_loss: 8.9559e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00090, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/01-0.00090.hdf5\n",
      "Epoch 2/30\n",
      "148826/148826 [==============================] - 334s 2ms/step - loss: 0.0017 - val_loss: 8.9511e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00090 to 0.00090, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/02-0.00090.hdf5\n",
      "Epoch 3/30\n",
      "148826/148826 [==============================] - 312s 2ms/step - loss: 0.0017 - val_loss: 8.9195e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00090 to 0.00089, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/03-0.00089.hdf5\n",
      "Epoch 4/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 8.9587e-04\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00089\n",
      "Epoch 5/30\n",
      "148826/148826 [==============================] - 306s 2ms/step - loss: 0.0017 - val_loss: 8.8988e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00089 to 0.00089, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/05-0.00089.hdf5\n",
      "Epoch 6/30\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 0.0017 - val_loss: 8.9541e-04\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00089\n",
      "Epoch 7/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 8.8731e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00089 to 0.00089, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/07-0.00089.hdf5\n",
      "Epoch 8/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 8.9295e-04\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00089\n",
      "Epoch 9/30\n",
      "148826/148826 [==============================] - 305s 2ms/step - loss: 0.0017 - val_loss: 8.9534e-04\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00089\n",
      "Epoch 10/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 8.9873e-04\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00089\n",
      "Epoch 11/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 0.0017 - val_loss: 8.9224e-04\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00089\n",
      "Epoch 12/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 8.8590e-04\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00089 to 0.00089, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/12-0.00089.hdf5\n",
      "Epoch 13/30\n",
      "148826/148826 [==============================] - 306s 2ms/step - loss: 0.0017 - val_loss: 9.0012e-04\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00089\n",
      "Epoch 14/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 0.0017 - val_loss: 9.0255e-04\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00089\n",
      "Epoch 15/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 0.0017 - val_loss: 8.9239e-04\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00089\n",
      "Epoch 16/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0017 - val_loss: 9.0031e-04\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00089\n",
      "Epoch 17/30\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 0.0017 - val_loss: 8.8533e-04\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00089 to 0.00089, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/17-0.00089.hdf5\n",
      "Epoch 18/30\n",
      "148826/148826 [==============================] - 307s 2ms/step - loss: 0.0017 - val_loss: 8.8278e-04\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00089 to 0.00088, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/18-0.00088.hdf5\n",
      "Epoch 19/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 0.0016 - val_loss: 6.6549e-04\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00088 to 0.00067, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/19-0.00067.hdf5\n",
      "Epoch 20/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 0.0012 - val_loss: 5.6553e-04\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00067 to 0.00057, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/20-0.00057.hdf5\n",
      "Epoch 21/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 0.0011 - val_loss: 5.1558e-04\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00057 to 0.00052, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/21-0.00052.hdf5\n",
      "Epoch 22/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 9.9308e-04 - val_loss: 4.8548e-04\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00052 to 0.00049, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/22-0.00049.hdf5\n",
      "Epoch 23/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 9.4162e-04 - val_loss: 4.5979e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00049 to 0.00046, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/23-0.00046.hdf5\n",
      "Epoch 24/30\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 9.0237e-04 - val_loss: 4.3970e-04\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00046 to 0.00044, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/24-0.00044.hdf5\n",
      "Epoch 25/30\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 8.7042e-04 - val_loss: 4.2421e-04\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00044 to 0.00042, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/25-0.00042.hdf5\n",
      "Epoch 26/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 8.4345e-04 - val_loss: 4.0815e-04\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00042 to 0.00041, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/26-0.00041.hdf5\n",
      "Epoch 27/30\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 8.2019e-04 - val_loss: 3.9503e-04\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00041 to 0.00040, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/27-0.00040.hdf5\n",
      "Epoch 28/30\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 7.9977e-04 - val_loss: 3.8466e-04\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00040 to 0.00038, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/28-0.00038.hdf5\n",
      "Epoch 29/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 7.8141e-04 - val_loss: 3.7337e-04\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00038 to 0.00037, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/29-0.00037.hdf5\n",
      "Epoch 30/30\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 7.6462e-04 - val_loss: 3.6048e-04\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00037 to 0.00036, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/30-0.00036.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "MODEL_SAVE_FOLDER_PATH = '/home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.5f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                                verbose=1, save_best_only=True)\n",
    "hist = model.fit(x=r, y=r_y,\n",
    "                 validation_data=(val_r_x, val_r_y),\n",
    "                  epochs=30,\n",
    "                  batch_size=32,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[cb_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148826 samples, validate on 23015 samples\n",
      "Epoch 1/10\n",
      "148826/148826 [==============================] - 307s 2ms/step - loss: 7.4921e-04 - val_loss: 3.5359e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00035, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/01-0.000354.hdf5\n",
      "Epoch 2/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 7.3509e-04 - val_loss: 3.4358e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00035 to 0.00034, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/02-0.000344.hdf5\n",
      "Epoch 3/10\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 7.2197e-04 - val_loss: 3.3515e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00034 to 0.00034, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/03-0.000335.hdf5\n",
      "Epoch 4/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 7.0956e-04 - val_loss: 3.2701e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00034 to 0.00033, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/04-0.000327.hdf5\n",
      "Epoch 5/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 6.9811e-04 - val_loss: 3.1879e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00033 to 0.00032, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/05-0.000319.hdf5\n",
      "Epoch 6/10\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 6.8780e-04 - val_loss: 3.1220e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00032 to 0.00031, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/06-0.000312.hdf5\n",
      "Epoch 7/10\n",
      "148826/148826 [==============================] - 311s 2ms/step - loss: 6.7727e-04 - val_loss: 3.0452e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00031 to 0.00030, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/07-0.000305.hdf5\n",
      "Epoch 8/10\n",
      "148826/148826 [==============================] - 308s 2ms/step - loss: 6.6755e-04 - val_loss: 3.0042e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00030 to 0.00030, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/08-0.000300.hdf5\n",
      "Epoch 9/10\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 6.5868e-04 - val_loss: 2.9188e-04\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00030 to 0.00029, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/09-0.000292.hdf5\n",
      "Epoch 10/10\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 6.5024e-04 - val_loss: 2.8797e-04\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00029 to 0.00029, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/10-0.000288.hdf5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "MODEL_SAVE_FOLDER_PATH = '/home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "  os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.6f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                                verbose=1, save_best_only=True)\n",
    "hist1 = model.fit(x=r, y=r_y,\n",
    "                 validation_data=(val_r_x, val_r_y),\n",
    "                  epochs=10,\n",
    "                  batch_size=32,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[cb_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148826 samples, validate on 23015 samples\n",
      "Epoch 1/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 6.4192e-04 - val_loss: 2.8060e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00028, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/01-0.0002806.hdf5\n",
      "Epoch 2/10\n",
      "148826/148826 [==============================] - 311s 2ms/step - loss: 6.3390e-04 - val_loss: 2.7525e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00028 to 0.00028, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/02-0.0002753.hdf5\n",
      "Epoch 3/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 6.2645e-04 - val_loss: 2.6896e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00028 to 0.00027, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/03-0.0002690.hdf5\n",
      "Epoch 4/10\n",
      "148826/148826 [==============================] - 310s 2ms/step - loss: 6.1915e-04 - val_loss: 2.6417e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00027 to 0.00026, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/04-0.0002642.hdf5\n",
      "Epoch 5/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 6.1210e-04 - val_loss: 2.5901e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00026 to 0.00026, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/05-0.0002590.hdf5\n",
      "Epoch 6/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 6.0554e-04 - val_loss: 2.5556e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00026 to 0.00026, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/06-0.0002556.hdf5\n",
      "Epoch 7/10\n",
      "148826/148826 [==============================] - 311s 2ms/step - loss: 5.9935e-04 - val_loss: 2.5144e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00026 to 0.00025, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/07-0.0002514.hdf5\n",
      "Epoch 8/10\n",
      "148826/148826 [==============================] - 309s 2ms/step - loss: 5.9357e-04 - val_loss: 2.4826e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00025 to 0.00025, saving model to /home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/08-0.0002483.hdf5\n",
      "Epoch 9/10\n",
      "123168/148826 [=======================>......] - ETA: 49s - loss: 5.8514e-04"
     ]
    }
   ],
   "source": [
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# MODEL_SAVE_FOLDER_PATH = '/home/yjkim/new_melon_test/youngwook-melon/res/cmf/auto1/'\n",
    "# if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "#   os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.7f}.hdf5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss',\n",
    "                                verbose=1, save_best_only=True)\n",
    "hist2 = model.fit(x=r, y=r_y,\n",
    "                 validation_data=(val_r_x, val_r_y),\n",
    "                  epochs=10,\n",
    "                  batch_size=32,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[cb_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_vloss = hist.history['val_loss']\n",
    "y_loss = hist.history['loss']\n",
    "\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/home/yjkim/yj_melon/test/Recommenders/reco_utils/recommender/ncf/movie/newcount/64-0.0006.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b5d422c9a226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/yjkim/yj_melon/test/Recommenders/reco_utils/recommender/ncf/movie/newcount/64-0.0006.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/allml/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allml/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allml/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/allml/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/home/yjkim/yj_melon/test/Recommenders/reco_utils/recommender/ncf/movie/newcount/64-0.0006.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"/home/yjkim/yj_melon/test/Recommenders/reco_utils/recommender/ncf/movie/newcount/64-0.0006.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val\n",
    "t_val = []\n",
    "s_val = []\n",
    "play_val = []\n",
    "for i in range(len(val)):\n",
    "    t_val.append(val[i][\"tags\"])\n",
    "    s_val.append(val[i][\"songs\"])\n",
    "    play_val.append(val[i][\"plylst_title\"])\n",
    "\n",
    "songs_val = []\n",
    "for i in s_val:\n",
    "    abc = []\n",
    "    for j in i:\n",
    "        abc.append(str(j))  \n",
    "    songs_val.append(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_v = [' '.join(sentence) for sentence in songs_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_val_data  = vect_s.transform(songs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23015x156348 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 365022 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "a= []\n",
    "d = 1\n",
    "for _list in songs:\n",
    "    sample_list = []\n",
    "    if len(_list) < 9:\n",
    "        a.append(_list)\n",
    "        d\n",
    "        continue\n",
    "    for i in range(1):\n",
    "        new_list = copy.deepcopy(_list)\n",
    "        for i in range(int(len(new_list) *0.3)):\n",
    "            new_list.remove(random.choice(new_list))\n",
    "        a.append(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<23015x156348 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 365022 stored elements in Compressed Sparse Row format>,\n",
       " <23015x156348 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 266101 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_y_,val_data_x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tname = vect.get_feature_names\n",
    "def recommender_for_user(user_id, interact_matrix,  topn = 10):\n",
    "\n",
    "    pred_scores = interact_matrix.loc[user_id].values\n",
    "    #print(pred_scores,len(pred_scores),df.columns[57061:],len(df.columns[57061:]))\n",
    "    df_scores   = pd.DataFrame({'content_id': tname, \n",
    "                               'score': pred_scores})\n",
    "\n",
    "    df_rec      = df_scores.set_index('content_id')\\\n",
    "                    .sort_values('score', ascending=False)\\\n",
    "                    .head(topn)[[\"score\"]]\n",
    "    return df_rec[df_rec.score > 0]\n",
    "fname = vect_s.get_feature_names()\n",
    "def recommender_for_user_s(user_id, interact_matrix,  topn = 100):\n",
    "    \n",
    "    pred_scores = interact_matrix.loc[user_id].values\n",
    "    #print(pred_scores)\n",
    "    #print(list(song_predict)[0:10])\n",
    "    df_scores   = pd.DataFrame({'content_id': fname, \n",
    "                               'score': pred_scores})\n",
    "\n",
    "    df_rec      = df_scores.set_index('content_id')\\\n",
    "                    .sort_values('score', ascending=False)\\\n",
    "                    .head(topn)[[\"score\"]]\n",
    "    return df_rec[df_rec.score > 0]\n",
    "def select_top_n(names, scores, topn):\n",
    "    #return sorted(enumerate(names), key=lambda item: scores[item[0]], reverse=True)\n",
    "    return list(zip(*sorted(enumerate(names), key=lambda item: scores[item[0]], reverse=True)[:topn]))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "val_copy = copy.deepcopy(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5423it [18:24,  5.07it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "for i,check in tqdm(enumerate(model.predict(val_data_y_))):\n",
    "    new_matrix = (val_data_y_[i].toarray()==0)*(check - np.min(check))\n",
    "    #val_copy[i][\"songs\"] = select_top_n(names = fname, scores=new_matrix[0,:], topn=100)\n",
    "    \n",
    "    \n",
    "    song_predict = pd.DataFrame(new_matrix[:,:])\n",
    "    #print(\"Model prediction00: {}s\".format(time.time() - start_time))\n",
    "    #start_time = time.time()\n",
    "\n",
    "    song_predict.columns=fname\n",
    "    #print(\"Model prediction01: {}s\".format(time.time() - start_time))\n",
    "    #start_time = time.time()\n",
    "\n",
    "\n",
    "    #print(\"Model prediction2: {}s\".format(time.time() - start_time))\n",
    "    #start_time = time.time()\n",
    "\n",
    "    #tags_predict = pd.DataFrame(new_matrix[:,615142:])\n",
    "    #tags_predict.columns=vect.get_feature_names()\n",
    "    #print(recommender_for_user(user_id = i, interact_matrix = df)[\"score\"].index.tolist())\n",
    "    #print(val_[i][\"songs\"])\n",
    "    #val[i][\"tags\"] = recommender_for_user(user_id = 0, interact_matrix = tags_predict)[\"score\"].index.tolist()\n",
    "    val_copy[i][\"songs\"] = recommender_for_user_s(user_id = 0, interact_matrix = song_predict)[\"score\"].index.tolist()\n",
    "#     print(\"Model prediction3: {}s\".format(time.time() - start_time))\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     print(val[i][\"songs\"] == top_songs, top_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [],\n",
       " 'id': 45144,\n",
       " 'plylst_title': '',\n",
       " 'songs': ['152422',\n",
       "  '643628',\n",
       "  '610933',\n",
       "  '224921',\n",
       "  '205179',\n",
       "  '215411',\n",
       "  '427724',\n",
       "  '209135',\n",
       "  '497066',\n",
       "  '463173',\n",
       "  '627363',\n",
       "  '485155',\n",
       "  '680366',\n",
       "  '116573',\n",
       "  '424813',\n",
       "  '449244',\n",
       "  '11657',\n",
       "  '366786',\n",
       "  '357367',\n",
       "  '645489',\n",
       "  '90557',\n",
       "  '349492',\n",
       "  '547967',\n",
       "  '523521',\n",
       "  '396828',\n",
       "  '675115',\n",
       "  '235773',\n",
       "  '663256',\n",
       "  '668128',\n",
       "  '174749',\n",
       "  '674160',\n",
       "  '422077',\n",
       "  '648628',\n",
       "  '169984',\n",
       "  '672550',\n",
       "  '531820',\n",
       "  '154858',\n",
       "  '520093',\n",
       "  '654757',\n",
       "  '207558',\n",
       "  '407828',\n",
       "  '701557',\n",
       "  '153271',\n",
       "  '187047',\n",
       "  '42155',\n",
       "  '442014',\n",
       "  '19811',\n",
       "  '144663',\n",
       "  '582252',\n",
       "  '581799',\n",
       "  '554751',\n",
       "  '44603',\n",
       "  '117595',\n",
       "  '464051',\n",
       "  '339802',\n",
       "  '486705',\n",
       "  '300087',\n",
       "  '350309',\n",
       "  '518420',\n",
       "  '253755',\n",
       "  '133143',\n",
       "  '246531',\n",
       "  '209993',\n",
       "  '448116',\n",
       "  '15124',\n",
       "  '307896',\n",
       "  '295250',\n",
       "  '553171',\n",
       "  '177460',\n",
       "  '6546',\n",
       "  '571016',\n",
       "  '76888',\n",
       "  '118219',\n",
       "  '202564',\n",
       "  '653733',\n",
       "  '678762',\n",
       "  '625875',\n",
       "  '626369',\n",
       "  '422915',\n",
       "  '341513',\n",
       "  '348200',\n",
       "  '13281',\n",
       "  '509998',\n",
       "  '95485',\n",
       "  '131310',\n",
       "  '27469',\n",
       "  '37748',\n",
       "  '41912',\n",
       "  '212654',\n",
       "  '152475',\n",
       "  '318762',\n",
       "  '705515',\n",
       "  '68348',\n",
       "  '549178',\n",
       "  '245317',\n",
       "  '67655',\n",
       "  '409058',\n",
       "  '246984',\n",
       "  '199262',\n",
       "  '414940'],\n",
       " 'like_cnt': 20,\n",
       " 'updt_date': '2017-10-30 18:15:43.000'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_copy[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': [],\n",
       " 'id': 45144,\n",
       " 'plylst_title': '',\n",
       " 'songs': ['288763',\n",
       "  '618392',\n",
       "  '396828',\n",
       "  '284992',\n",
       "  '351888',\n",
       "  '442014',\n",
       "  '668720',\n",
       "  '348398',\n",
       "  '661449',\n",
       "  '198487',\n",
       "  '522350',\n",
       "  '70185',\n",
       "  '491536',\n",
       "  '105140',\n",
       "  '624827',\n",
       "  '4185',\n",
       "  '549392',\n",
       "  '672541',\n",
       "  '349492',\n",
       "  '199262',\n",
       "  '479944',\n",
       "  '404524',\n",
       "  '451359',\n",
       "  '586684',\n",
       "  '131701',\n",
       "  '367963',\n",
       "  '10961',\n",
       "  '625254',\n",
       "  '622923',\n",
       "  '305045',\n",
       "  '509998',\n",
       "  '106017',\n",
       "  '442543',\n",
       "  '71727',\n",
       "  '453718',\n",
       "  '123485',\n",
       "  '205247',\n",
       "  '663492',\n",
       "  '61170',\n",
       "  '683085',\n",
       "  '324779',\n",
       "  '289121',\n",
       "  '297924',\n",
       "  '174749',\n",
       "  '113664',\n",
       "  '29035',\n",
       "  '64930',\n",
       "  '41404',\n",
       "  '513756',\n",
       "  '642555',\n",
       "  '662914',\n",
       "  '214494',\n",
       "  '87722',\n",
       "  '215132',\n",
       "  '218839',\n",
       "  '49147',\n",
       "  '102980',\n",
       "  '527296',\n",
       "  '384299',\n",
       "  '28788',\n",
       "  '24257',\n",
       "  '388675',\n",
       "  '210',\n",
       "  '701323',\n",
       "  '333232',\n",
       "  '422915',\n",
       "  '56352',\n",
       "  '331958',\n",
       "  '535399',\n",
       "  '498219',\n",
       "  '495890',\n",
       "  '482716',\n",
       "  '582252',\n",
       "  '61159',\n",
       "  '443425',\n",
       "  '253425',\n",
       "  '345321',\n",
       "  '241002',\n",
       "  '325233',\n",
       "  '21725',\n",
       "  '131295',\n",
       "  '240250',\n",
       "  '162052',\n",
       "  '144663',\n",
       "  '123837',\n",
       "  '675823',\n",
       "  '564698',\n",
       "  '227867',\n",
       "  '152422',\n",
       "  '165230',\n",
       "  '454622',\n",
       "  '408772',\n",
       "  '20398',\n",
       "  '459543',\n",
       "  '478754',\n",
       "  '284879',\n",
       "  '75971',\n",
       "  '616038',\n",
       "  '683396',\n",
       "  '196653'],\n",
       " 'like_cnt': 20,\n",
       " 'updt_date': '2017-10-30 18:15:43.000'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_copy[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"UTF-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "#dap2 = load_json(\"2.json\")\n",
    "dap50 = load_json(\"dab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dap50)):\n",
    "    dap50[i][\"songs\"] = val_copy[i][\"songs\"]\n",
    "    \n",
    "for i in range(len(dap50)):\n",
    "    for j in range(len(dap50[i][\"songs\"])):\n",
    "        dap50[i][\"songs\"][j] = int(dap50[i][\"songs\"][j])\n",
    "        \n",
    "        \n",
    "with open(\"resu_t.json\", \"w\") as outfile:\n",
    "        json.dump(dap50, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 45144,\n",
       " 'songs': [144663,\n",
       "  367963,\n",
       "  174749,\n",
       "  357367,\n",
       "  171798,\n",
       "  497066,\n",
       "  697100,\n",
       "  116573,\n",
       "  295250,\n",
       "  418935,\n",
       "  610933,\n",
       "  224921,\n",
       "  245317,\n",
       "  446812,\n",
       "  178044,\n",
       "  553171,\n",
       "  440160,\n",
       "  6546,\n",
       "  246531,\n",
       "  576186,\n",
       "  224609,\n",
       "  531820,\n",
       "  281838,\n",
       "  10961,\n",
       "  608260,\n",
       "  377243,\n",
       "  45476,\n",
       "  449244,\n",
       "  623725,\n",
       "  77951,\n",
       "  668763,\n",
       "  232874,\n",
       "  586653,\n",
       "  67655,\n",
       "  478754,\n",
       "  210647,\n",
       "  112153,\n",
       "  423649,\n",
       "  532347,\n",
       "  305045,\n",
       "  185174,\n",
       "  283138,\n",
       "  19533,\n",
       "  102980,\n",
       "  244565,\n",
       "  322491,\n",
       "  495830,\n",
       "  122363,\n",
       "  165281,\n",
       "  398805,\n",
       "  582252,\n",
       "  516653,\n",
       "  234921,\n",
       "  553786,\n",
       "  182201,\n",
       "  366786,\n",
       "  562482,\n",
       "  333070,\n",
       "  284992,\n",
       "  339802,\n",
       "  384059,\n",
       "  27469,\n",
       "  343974,\n",
       "  283780,\n",
       "  125822,\n",
       "  482716,\n",
       "  37748,\n",
       "  234999,\n",
       "  278995,\n",
       "  532114,\n",
       "  443902,\n",
       "  627363,\n",
       "  321643,\n",
       "  43471,\n",
       "  707724,\n",
       "  334539,\n",
       "  519391,\n",
       "  611737,\n",
       "  140130,\n",
       "  594592,\n",
       "  564336,\n",
       "  567650,\n",
       "  13281,\n",
       "  298103,\n",
       "  701557,\n",
       "  286273,\n",
       "  549392,\n",
       "  50428,\n",
       "  486705,\n",
       "  17107,\n",
       "  166841,\n",
       "  581789,\n",
       "  98472,\n",
       "  505036,\n",
       "  509998,\n",
       "  307896,\n",
       "  351888,\n",
       "  596663,\n",
       "  450661,\n",
       "  675115],\n",
       " 'tags': ['이별', '사랑', '발라드', '감성', '기분전환', '새벽', '눈물', '카페', '잔잔한', '비오는날']}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dap50[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x156348 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[0][\"songs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyDeep",
   "language": "python",
   "name": "easydeep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
